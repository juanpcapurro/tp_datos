{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sbn\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import time\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from pandas.api.types import CategoricalDtype\n",
    "\n",
    "%matplotlib inline\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "plt.style.use('default') \n",
    "sbn.set(style=\"whitegrid\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Satinización de archivos de edad y genero**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vasectomio/.virtualenv/datos/lib/python3.6/site-packages/ipykernel_launcher.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/vasectomio/.virtualenv/datos/lib/python3.6/site-packages/ipykernel_launcher.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/vasectomio/.virtualenv/datos/lib/python3.6/site-packages/ipykernel_launcher.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/vasectomio/.virtualenv/datos/lib/python3.6/site-packages/ipykernel_launcher.py:27: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "idpostulante    False\n",
      "nombre          False\n",
      "estado          False\n",
      "dtype: bool\n",
      "False    137072\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Antes que nada, me intriga si los archivos de 'datos_navent' y los de 'hasta15/4' tienen overlap, son redundantes o consecutivos\n",
    "genero_edad_postulantes = pd.read_csv(\n",
    "    'datos/datos_navent/fiuba_2_postulantes_genero_y_edad.csv'\n",
    ").merge(\n",
    "    pd.read_csv('datos/hasta_15_4/fiuba_2_postulantes_genero_y_edad.csv'),\n",
    "    on=['idpostulante','fechanacimiento','sexo'],\n",
    "    how='outer'\n",
    ")\n",
    "def postulantes_str2timestamp(s): # debo\n",
    "    if type(s) is datetime:\n",
    "        return s\n",
    "    try:\n",
    "        return datetime.strptime(s, '%Y-%m-%d')\n",
    "    except:\n",
    "        return None\n",
    "#veo que hay repetidos por id\n",
    "#veo que hay gente (4) con sexo '0'\n",
    "# Genero una funcion para satinizar archivos de postulantes_genero_edad\n",
    "genero_categoria = CategoricalDtype(categories=[\"MASC\",\"FEM\",\"NO_DECLARA\"], ordered=False)\n",
    "def satinize_postulante_genero_edad(df):\n",
    "    df['sexo'] = df['sexo'].astype(genero_categoria).fillna(\"NO_DECLARA\")\n",
    "    df = df.drop_duplicates(subset='idpostulante')\n",
    "    df['fechanacimiento']= df['fechanacimiento'].map(postulantes_str2timestamp)\n",
    "    mean_datetime = datetime.now()\n",
    "    df['fechanacimiento']= df['fechanacimiento'].map(lambda it: it if it else mean_datetime)\n",
    "    df['edad'] = df.fechanacimiento.apply(lambda it: 2018 - it.year)\n",
    "    df = df[df.edad >17][df.edad<105]\n",
    "    return df\n",
    "genero_edad_postulantes = satinize_postulante_genero_edad(genero_edad_postulantes)\n",
    "genero_edad_postulantes.shape[0]\n",
    "educacion_postulantes = pd.read_csv(\n",
    "    'datos/datos_navent/fiuba_1_postulantes_educacion.csv'\n",
    ").merge(pd.read_csv('datos/hasta_15_4/fiuba_1_postulantes_educacion.csv'))\n",
    "print(educacion_postulantes.isna().any()) #no hay nulos\n",
    "print(educacion_postulantes.duplicated().value_counts())#ni duplicados\n",
    "def generar_nivel_educativo(postulantes, educacion):\n",
    "    #Considero como nivel educativo el maximo nivel que alcanzaron que fue completado.\n",
    "    #Descarto estudios en curso o abandonados, quizas deba volver aca en algun momento\n",
    "    tipo_estudio = CategoricalDtype(\n",
    "        categories=[\"Otro\",\"Secundario\",\"Terciario/Técnico\",\"Universitario\",\"Posgrado\",\"Master\",\"Doctorado\"],\n",
    "        ordered=True\n",
    "    )\n",
    "    educacion = educacion[educacion.estado=='Graduado'].drop(['estado'],1)\n",
    "    educacion.nombre= educacion.nombre.astype(tipo_estudio)\n",
    "    educacion = educacion.sort_values(by='nombre',ascending=True)\n",
    "    educacion = educacion.drop_duplicates(subset='idpostulante',keep='last')\n",
    "    postulantes = postulantes.merge(educacion, on='idpostulante')\n",
    "    postulantes = postulantes.rename(index=str,columns={'nombre':'nivel_educativo'})\n",
    "    return postulantes.copy()\n",
    "postulantes = generar_nivel_educativo(genero_edad_postulantes, educacion_postulantes)\n",
    "del genero_edad_postulantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nulos:  idaviso         False\n",
      "timestamp       False\n",
      "idpostulante    False\n",
      "dtype: bool\n",
      "duplicados:  False    6682624\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "vistas = pd.concat([\n",
    "    pd.read_csv('datos/hasta_15_4/fiuba_3_vistas.csv'),\n",
    "    pd.read_csv('datos/datos_navent/fiuba_3_vistas.csv')\n",
    "]).drop_duplicates().rename(columns={'idAviso': 'idaviso'})\n",
    "vistas.idaviso = vistas.idaviso.astype('int64')\n",
    "print(\"nulos: \",vistas.isna().any()) #no hay nulos\n",
    "print(\"duplicados: \",vistas.duplicated().value_counts())#ni duplicados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def agregar_cantidad_anuncios(df, nombre_columna, anuncios):\n",
    "    values = pd.DataFrame()\n",
    "    value_counts = anuncios['idpostulante'].value_counts()\n",
    "    values['idpostulante'] = value_counts.index\n",
    "    values[nombre_columna] = value_counts.values\n",
    "    df = pd.merge(df,values, on='idpostulante',how='left')\n",
    "    df[nombre_columna] = df[nombre_columna].fillna(0)\n",
    "    return df\n",
    "postulantes = agregar_cantidad_anuncios(postulantes, 'anuncios_vistos', vistas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## postulaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method DataFrame.count of             idaviso idpostulante     fechapostulacion\n",
      "0        1112286523         ZaO5  2018-01-24 15:07:39\n",
      "1        1112272060         ZaO5  2018-01-24 15:20:10\n",
      "2        1112288401         ZaO5  2018-01-26 08:37:04\n",
      "3        1112300563         ZaO5  2018-01-30 13:35:48\n",
      "4        1112293018         ZaO5  2018-01-31 08:41:05\n",
      "5        1112301287         ZaO5  2018-01-31 08:55:20\n",
      "6        1112309589         ZaO5  2018-02-03 15:55:15\n",
      "7        1112317020         ZaO5  2018-02-07 09:56:22\n",
      "8        1112322363         ZaO5  2018-02-09 10:29:54\n",
      "9        1112327122         ZaO5  2018-02-11 17:49:26\n",
      "10       1112315062         ZaO5  2018-02-11 18:08:14\n",
      "11       1112348722         ZaO5  2018-02-21 19:53:24\n",
      "12       1112347076         ZaO5  2018-02-21 20:10:19\n",
      "13       1112346704         ZaO5  2018-02-21 20:15:35\n",
      "14       1112346547         ZaO5  2018-02-21 20:17:29\n",
      "15       1112335122         ZaO5  2018-02-21 20:23:19\n",
      "16       1112350663         ZaO5  2018-02-21 20:25:29\n",
      "17       1112346564         ZaO5  2018-02-21 20:26:54\n",
      "18       1112343977         ZaO5  2018-02-21 20:29:24\n",
      "19       1112345203         ZaO5  2018-02-21 20:29:54\n",
      "20       1112303217         ZaO5  2018-02-21 20:30:29\n",
      "21       1112345900         ZaO5  2018-02-21 20:33:00\n",
      "22       1112364763         ZaO5  2018-02-27 20:54:50\n",
      "23       1112261212         NdJl  2018-01-16 08:50:30\n",
      "24       1112273308         NdJl  2018-01-23 07:53:47\n",
      "25       1112281548         NdJl  2018-01-24 05:10:12\n",
      "26       1112260409         NdJl  2018-01-24 05:17:29\n",
      "27       1112293547         NdJl  2018-01-29 15:41:43\n",
      "28       1112287915         NdJl  2018-01-29 15:42:39\n",
      "29       1112303880         NdJl  2018-01-31 15:16:48\n",
      "...             ...          ...                  ...\n",
      "1706700  1112336254      qe21A9X  2018-02-28 22:30:47\n",
      "1706701  1112314018      qe21A9X  2018-02-28 22:35:30\n",
      "1706702  1111890741      qe21A9X  2018-02-28 22:39:21\n",
      "1706703  1112340866      qe21A9X  2018-02-28 22:40:01\n",
      "1706704  1112347055      2zP6J11  2018-02-28 22:22:39\n",
      "1706705  1112369432      8MPox8j  2018-02-28 22:52:13\n",
      "1706706  1112362468      8MPox8j  2018-02-28 23:26:51\n",
      "1706707  1110478766      zvabpEJ  2018-02-28 22:47:13\n",
      "1706708  1112186855      8MPoxGz  2018-02-28 22:45:24\n",
      "1706709  1112367875      8MPoxGz  2018-02-28 22:55:00\n",
      "1706710  1112364777      8MPoxGz  2018-02-28 22:59:25\n",
      "1706711  1111636821      8MPoxGz  2018-02-28 23:00:02\n",
      "1706712  1111414561      8MPoxGz  2018-02-28 23:02:17\n",
      "1706713  1112361855      ow2p8Wr  2018-02-28 22:56:30\n",
      "1706714  1112369825      pzdkx1p  2018-02-28 22:38:12\n",
      "1706715  1112359807      akjVlK9  2018-02-28 22:51:04\n",
      "1706716  1112152590      vVja48E  2018-02-28 22:57:51\n",
      "1706717  1112368214      ow2p8vk  2018-02-28 23:13:17\n",
      "1706718  1112369739      mzdNo99  2018-02-28 22:59:12\n",
      "1706719  1112369774      Nzr1J34  2018-02-28 22:57:20\n",
      "1706720  1112369571      Nzr1J34  2018-02-28 23:05:40\n",
      "1706721  1112364915      mzdNorY  2018-02-28 23:49:06\n",
      "1706722  1112241774      mzdNorY  2018-02-28 23:54:42\n",
      "1706723  1112341154      mzdNorY  2018-02-28 23:58:14\n",
      "1706724  1112348533      6rPEvzO  2018-02-28 23:27:25\n",
      "1706725  1112369306      ow2p8Z0  2018-02-28 23:23:36\n",
      "1706726  1112367705      ow2p8Z0  2018-02-28 23:23:57\n",
      "1706727  1112366909      ow2p8Z0  2018-02-28 23:26:49\n",
      "1706728  1112308651      8MPoxDW  2018-02-28 23:52:13\n",
      "1706729  1112341128      8MPoxDW  2018-02-28 23:59:06\n",
      "\n",
      "[1706730 rows x 3 columns]>\n",
      "<bound method DataFrame.count of             idaviso idpostulante     fechapostulacion\n",
      "0        1112286523         ZaO5  2018-01-24 15:07:39\n",
      "1        1112272060         ZaO5  2018-01-24 15:20:10\n",
      "2        1112288401         ZaO5  2018-01-26 08:37:04\n",
      "3        1112300563         ZaO5  2018-01-30 13:35:48\n",
      "4        1112293018         ZaO5  2018-01-31 08:41:05\n",
      "5        1112301287         ZaO5  2018-01-31 08:55:20\n",
      "6        1112309589         ZaO5  2018-02-03 15:55:15\n",
      "7        1112317020         ZaO5  2018-02-07 09:56:22\n",
      "8        1112322363         ZaO5  2018-02-09 10:29:54\n",
      "9        1112327122         ZaO5  2018-02-11 17:49:26\n",
      "10       1112315062         ZaO5  2018-02-11 18:08:14\n",
      "11       1112348722         ZaO5  2018-02-21 19:53:24\n",
      "12       1112347076         ZaO5  2018-02-21 20:10:19\n",
      "13       1112346704         ZaO5  2018-02-21 20:15:35\n",
      "14       1112346547         ZaO5  2018-02-21 20:17:29\n",
      "15       1112335122         ZaO5  2018-02-21 20:23:19\n",
      "16       1112350663         ZaO5  2018-02-21 20:25:29\n",
      "17       1112346564         ZaO5  2018-02-21 20:26:54\n",
      "18       1112343977         ZaO5  2018-02-21 20:29:24\n",
      "19       1112345203         ZaO5  2018-02-21 20:29:54\n",
      "20       1112303217         ZaO5  2018-02-21 20:30:29\n",
      "21       1112345900         ZaO5  2018-02-21 20:33:00\n",
      "22       1112364763         ZaO5  2018-02-27 20:54:50\n",
      "23       1112261212         NdJl  2018-01-16 08:50:30\n",
      "24       1112273308         NdJl  2018-01-23 07:53:47\n",
      "25       1112281548         NdJl  2018-01-24 05:10:12\n",
      "26       1112260409         NdJl  2018-01-24 05:17:29\n",
      "27       1112293547         NdJl  2018-01-29 15:41:43\n",
      "28       1112287915         NdJl  2018-01-29 15:42:39\n",
      "29       1112303880         NdJl  2018-01-31 15:16:48\n",
      "...             ...          ...                  ...\n",
      "1706700  1112336254      qe21A9X  2018-02-28 22:30:47\n",
      "1706701  1112314018      qe21A9X  2018-02-28 22:35:30\n",
      "1706702  1111890741      qe21A9X  2018-02-28 22:39:21\n",
      "1706703  1112340866      qe21A9X  2018-02-28 22:40:01\n",
      "1706704  1112347055      2zP6J11  2018-02-28 22:22:39\n",
      "1706705  1112369432      8MPox8j  2018-02-28 22:52:13\n",
      "1706706  1112362468      8MPox8j  2018-02-28 23:26:51\n",
      "1706707  1110478766      zvabpEJ  2018-02-28 22:47:13\n",
      "1706708  1112186855      8MPoxGz  2018-02-28 22:45:24\n",
      "1706709  1112367875      8MPoxGz  2018-02-28 22:55:00\n",
      "1706710  1112364777      8MPoxGz  2018-02-28 22:59:25\n",
      "1706711  1111636821      8MPoxGz  2018-02-28 23:00:02\n",
      "1706712  1111414561      8MPoxGz  2018-02-28 23:02:17\n",
      "1706713  1112361855      ow2p8Wr  2018-02-28 22:56:30\n",
      "1706714  1112369825      pzdkx1p  2018-02-28 22:38:12\n",
      "1706715  1112359807      akjVlK9  2018-02-28 22:51:04\n",
      "1706716  1112152590      vVja48E  2018-02-28 22:57:51\n",
      "1706717  1112368214      ow2p8vk  2018-02-28 23:13:17\n",
      "1706718  1112369739      mzdNo99  2018-02-28 22:59:12\n",
      "1706719  1112369774      Nzr1J34  2018-02-28 22:57:20\n",
      "1706720  1112369571      Nzr1J34  2018-02-28 23:05:40\n",
      "1706721  1112364915      mzdNorY  2018-02-28 23:49:06\n",
      "1706722  1112241774      mzdNorY  2018-02-28 23:54:42\n",
      "1706723  1112341154      mzdNorY  2018-02-28 23:58:14\n",
      "1706724  1112348533      6rPEvzO  2018-02-28 23:27:25\n",
      "1706725  1112369306      ow2p8Z0  2018-02-28 23:23:36\n",
      "1706726  1112367705      ow2p8Z0  2018-02-28 23:23:57\n",
      "1706727  1112366909      ow2p8Z0  2018-02-28 23:26:49\n",
      "1706728  1112308651      8MPoxDW  2018-02-28 23:52:13\n",
      "1706729  1112341128      8MPoxDW  2018-02-28 23:59:06\n",
      "\n",
      "[1706730 rows x 3 columns]>\n",
      "      idaviso idpostulante     fechapostulacion\n",
      "0  1112286523         ZaO5  2018-01-24 15:07:39\n",
      "1  1112272060         ZaO5  2018-01-24 15:20:10\n",
      "2  1112288401         ZaO5  2018-01-26 08:37:04\n",
      "3  1112300563         ZaO5  2018-01-30 13:35:48\n",
      "4  1112293018         ZaO5  2018-01-31 08:41:05\n",
      "      idaviso idpostulante     fechapostulacion        date      time\n",
      "0  1112286523         ZaO5  2018-01-24 15:07:39  2018-01-24  15:07:39\n",
      "1  1112272060         ZaO5  2018-01-24 15:20:10  2018-01-24  15:20:10\n",
      "2  1112288401         ZaO5  2018-01-26 08:37:04  2018-01-26  08:37:04\n",
      "3  1112300563         ZaO5  2018-01-30 13:35:48  2018-01-30  13:35:48\n",
      "4  1112293018         ZaO5  2018-01-31 08:41:05  2018-01-31  08:41:05\n"
     ]
    }
   ],
   "source": [
    "postulaciones = pd.read_csv(\n",
    "    'datos/datos_navent/fiuba_4_postulaciones.csv'\n",
    ").merge(pd.read_csv('datos/hasta_15_4/fiuba_4_postulaciones.csv'))\n",
    "print(postulaciones.count)\n",
    "print(postulaciones.drop_duplicates().count) #no hay duplicados!\n",
    "print(postulaciones.head())\n",
    "def sanitize_postulaciones(df):\n",
    "    postulaciones['date'] = pd.to_datetime(postulaciones['fechapostulacion']).dt.date\n",
    "    postulaciones['time'] = pd.to_datetime(postulaciones['fechapostulacion']).dt.time\n",
    "    return postulaciones.copy()\n",
    "postulaciones = sanitize_postulaciones(postulaciones)\n",
    "print(postulaciones.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Archivo 'avisos_detalle'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "avisos_detalle = pd.concat([\n",
    "    pd.read_csv('datos/datos_navent/fiuba_6_avisos_detalle.csv'),\n",
    "    pd.read_csv('datos/hasta_15_4/fiuba_6_avisos_detalle.csv'),\n",
    "    pd.read_csv('datos/fiuba_6_avisos_detalle_missing_nivel_laboral.csv')\n",
    "])\n",
    "#ESTE DF TIENE MUCHOS DATOS NULOS EN LAS COLUMNAS DE 'CIUDAD' y 'MAPACALLE'. \n",
    "#Decidimos eliminarlas ya que no nos parecieron muy relevantes para el analisis\n",
    "#idpais solo tiene valor 1, la descripcion nunca es nula\n",
    "#avisos_detalle.drop('descripcion',1,inplace=True)\n",
    "tipo_trabajo = CategoricalDtype(\n",
    "    categories=[\"Full-time\",\"Part-time\",\"Teletrabajo\",\"Por Horas\",\"Pasantia\",\"Temporario\",\"Por Contrato\",\"Fines de Semana\",\"Primer empleo\"],\n",
    "    ordered=True #de 'mas fijo' a 'menos fijo'\n",
    ")\n",
    "avisos_detalle.nombre_area.value_counts()# hay muchas areas, no van a tener su propia categoria\n",
    "def sanitize_aviso_detalle(df):\n",
    "    df['tipo_de_trabajo'] = df['tipo_de_trabajo'].astype(tipo_trabajo)\n",
    "    #df.titulo = df.titulo.apply(lambda it: it.lower())\n",
    "    #df.descripcion = df.descripcion.apply(lambda it: it.lower())\n",
    "    for columna in ['nombre_zona','nombre_area','denominacion_empresa','nivel_laboral']:\n",
    "        df.loc[:,columna] = df.loc[:,columna].astype('category')\n",
    "    df.nivel_laboral = df.nivel_laboral.fillna('Otro')\n",
    "    df = df.drop_duplicates(subset='idaviso')\n",
    "    return df.drop(['ciudad','idpais','mapacalle'],1)\n",
    "avisos_detalle = sanitize_aviso_detalle(avisos_detalle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pruebo un random forest, con solamente las variables numericas/categoricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2591014, 13)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#no hace falta modificar el anuncio de postulantes\n",
    "avisos_forest =  avisos_detalle.drop(['titulo','descripcion'],1)\n",
    "postulaciones_forest = postulaciones.loc[:,['idaviso','idpostulante']]\n",
    "postulaciones_forest['sepostulo'] = 1\n",
    "joined = postulantes.drop(['fechanacimiento'],1).merge(\n",
    "    vistas.loc[:,['idpostulante','idaviso']],on='idpostulante',how='left'\n",
    ").merge(\n",
    "    avisos_forest,on='idaviso',how='left'\n",
    ").merge(\n",
    "    postulaciones_forest,on=['idaviso','idpostulante'],how='left'\n",
    ")\n",
    "joined.sepostulo = joined.sepostulo.fillna(0)\n",
    "joined['es_entrenamiento'] = np.random.uniform(0, 1, joined.shape[0]) <= 0.75\n",
    "features = [it for it in joined.columns if it not in ['idaviso','idpostulante','es_entrenamiento','sepostulo']]\n",
    "categorical_coulumns = joined.select_dtypes(['category']).columns\n",
    "joined[categorical_coulumns] = joined[categorical_coulumns].apply(lambda it: it.cat.codes)\n",
    "\n",
    "joined.shape\n",
    "#grouped = joined.groupby('idpostulante')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "features\n",
    "train, test = joined[joined.es_entrenamiento],joined[~joined.es_entrenamiento]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=3,\n",
       "            oob_score=False, random_state=0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = RandomForestClassifier(n_jobs=3, random_state=0)\n",
    "classifier.fit(train[features], train.sepostulo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8230637264600005"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame()\n",
    "results['prediccion'] = classifier.predict(test[features])\n",
    "results['baseline'] = [0 for i in range(test.shape[0])]\n",
    "results['verdad'] = test['sepostulo'].astype('int64').values\n",
    "test.sepostulo.isna().value_counts()\n",
    "results.verdad.isna().value_counts()\n",
    "roc_auc_score(y_true=test.sepostulo, y_score=results.prediccion.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'dtype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-b0507eb6a9c9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mjoined\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.virtualenv/datos/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   3612\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3613\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3614\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3615\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3616\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'dtype'"
     ]
    }
   ],
   "source": [
    "joined.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avisos_detalle.nombre_zona.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generar un resultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tentativa = pd.read_csv('datos/template_resultado.csv')\n",
    "submit = pd.DataFrame()\n",
    "submit['id'] = tentativa['id']\n",
    "submit = submit.set_index('id')\n",
    "submit['sepostulo'] =0\n",
    "submit.to_csv(path_or_buf='submit.csv')\n",
    "submit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defino los shingles de cada anuncio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shingles(string, n = 3):\n",
    "    return [string[i:i + n] for i in range(len(string) - n + 1)]\n",
    "\n",
    "def jaccard_similarity(list1, list2):\n",
    "    intersection = len(list(set(list1).intersection(list2)))\n",
    "    print(set(list1).intersection(list2))\n",
    "    union = (len(list1) + len(list2)) - intersection\n",
    "    print(union)\n",
    "    return float(intersection / union)\n",
    "#avisos_detalle['shingles_descripcion'] = avisos_detalle.descripcion.apply(shingles)\n",
    "#avisos_detalle['shingles_titulo'] = avisos_detalle.titulo.apply(shingles)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
