{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib_venn import venn2\n",
    "import numpy as np\n",
    "import seaborn as sbn\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import time\n",
    "import gc\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from pandas.api.types import CategoricalDtype\n",
    "\n",
    "%matplotlib inline\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "plt.style.use('default') \n",
    "sbn.set(style=\"whitegrid\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Satinización de archivos de edad y genero**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def postulantes_str2timestamp(s): # debo\n",
    "    if type(s) is datetime:\n",
    "        return s\n",
    "    try:\n",
    "        return datetime.strptime(s, '%Y-%m-%d')\n",
    "    except:\n",
    "        return None\n",
    "def sanitize_postulante_genero_edad(df):\n",
    "    df['sexo'] = df['sexo'].astype('category').fillna(\"NO_DECLARA\")\n",
    "    df = df.drop_duplicates(subset='idpostulante')\n",
    "    df['fechanacimiento']= df['fechanacimiento'].map(postulantes_str2timestamp)\n",
    "    mean_datetime = datetime.now()\n",
    "    df['fechanacimiento']= df['fechanacimiento'].map(lambda it: it if it else mean_datetime)\n",
    "    df['edad'] = df.fechanacimiento.apply(lambda it: 2018 - it.year)\n",
    "    df = df[df.edad >17][df.edad<105]\n",
    "    return df.drop(['fechanacimiento'],1)\n",
    "def generar_nivel_educativo(postulantes, educacion):\n",
    "    #Considero como nivel educativo el maximo nivel que alcanzaron que fue completado.\n",
    "    #Descarto estudios en curso o abandonados, quizas deba volver aca en algun momento\n",
    "    tipo_estudio = CategoricalDtype(\n",
    "        categories=[\"Otro\",\"Secundario\",\"Terciario/Técnico\",\"Universitario\",\"Posgrado\",\"Master\",\"Doctorado\"],\n",
    "        ordered=True\n",
    "    )\n",
    "    educacion = educacion[educacion.estado=='Graduado'].drop(['estado'],1)\n",
    "    educacion.nombre= educacion.nombre.astype(tipo_estudio)\n",
    "    educacion = educacion.sort_values(by='nombre',ascending=True)\n",
    "    educacion = educacion.drop_duplicates(subset='idpostulante',keep='last')\n",
    "    postulantes = postulantes.merge(educacion, on='idpostulante')\n",
    "    postulantes = postulantes.rename(index=str,columns={'nombre':'nivel_educativo'})\n",
    "    return postulantes.copy()\n",
    "def satinizar_vistas(vistas):\n",
    "    return vistas.drop_duplicates().rename(columns={'idAviso': 'idaviso'})\n",
    "\n",
    "def sanitize_aviso_detalle(df):\n",
    "    tipo_trabajo = CategoricalDtype(\n",
    "        categories=[\"Full-time\",\"Part-time\",\"Teletrabajo\",\"Por Horas\",\"Pasantia\",\"Temporario\",\"Por Contrato\",\"Fines de Semana\",\"Primer empleo\"],\n",
    "        ordered=True #de 'mas fijo' a 'menos fijo'\n",
    "    )\n",
    "    df['tipo_de_trabajo'] = df['tipo_de_trabajo'].astype(tipo_trabajo)\n",
    "    # el numero quizas amerite tratarse como hiperparametro\n",
    "    #empresas_reconocidas = df.denominacion_empresa.value_counts().index[:100]\n",
    "    #df.loc[:,'denominacion_empresa'] = df.denominacion_empresa.apply(lambda it: it if it in empresas_reconocidas else 'Otro')\n",
    "    popularidad_empresa = CategoricalDtype(\n",
    "        categories=df.denominacion_empresa.value_counts(ascending=True).index,\n",
    "        ordered=True\n",
    "    )\n",
    "    df.loc[:,'denominacion_empresa'] = df.loc[:,'denominacion_empresa'].astype(popularidad_empresa)\n",
    "    for columna in ['nombre_zona','nombre_area','nivel_laboral']:\n",
    "        df.loc[:,columna] = df.loc[:,columna].astype('category')\n",
    "    #df.nivel_laboral = df.nivel_laboral.fillna('Otro')\n",
    "    #df.denominacion_empresa = df.denominacion_empresa.fillna('Otro')\n",
    "    df = df.drop_duplicates(subset='idaviso')\n",
    "    return df.drop(['ciudad','idpais','mapacalle'],1)\n",
    "def sanitize_postulaciones(df):\n",
    "    df['date'] = pd.to_datetime(df['fechapostulacion']).dt.date\n",
    "    df['time'] = pd.to_datetime(df['fechapostulacion']).dt.time\n",
    "    return df\n",
    "def agregar_cantidad_anuncios(df, nombre_columna, anuncios):\n",
    "    values = pd.DataFrame()\n",
    "    value_counts = anuncios['idpostulante'].value_counts()\n",
    "    values['idpostulante'] = value_counts.index\n",
    "    values[nombre_columna] = value_counts.values\n",
    "    df = pd.merge(df,values, on='idpostulante',how='left')\n",
    "    df[nombre_columna] = df[nombre_columna].fillna(0)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Antes que nada, me intriga si los archivos de 'datos_navent' y los de 'hasta15/4' tienen overlap, son redundantes o consecutivos\n",
    "def leer_datos_entrenamiento():\n",
    "    genero_edad_postulantes = pd.read_csv(\n",
    "        'datos/datos_navent/fiuba_2_postulantes_genero_y_edad.csv'\n",
    "    ).merge(\n",
    "        pd.read_csv('datos/hasta_15_4/fiuba_2_postulantes_genero_y_edad.csv'),\n",
    "        on=['idpostulante','fechanacimiento','sexo'],\n",
    "        how='outer'\n",
    "    )\n",
    "    #veo que hay repetidos por id\n",
    "    #veo que hay gente (4) con sexo '0'\n",
    "    # Genero una funcion para satinizar archivos de postulantes_genero_edad\n",
    "    genero_edad_postulantes = sanitize_postulante_genero_edad(genero_edad_postulantes)\n",
    "    educacion_postulantes = pd.read_csv(\n",
    "        'datos/datos_navent/fiuba_1_postulantes_educacion.csv'\n",
    "    ).merge(pd.read_csv('datos/hasta_15_4/fiuba_1_postulantes_educacion.csv'))\n",
    "    postulantes = generar_nivel_educativo(genero_edad_postulantes, educacion_postulantes)\n",
    "    vistas = pd.concat([\n",
    "        pd.read_csv('datos/hasta_15_4/fiuba_3_vistas.csv'),\n",
    "        pd.read_csv('datos/datos_navent/fiuba_3_vistas.csv')\n",
    "    ])\n",
    "    vistas = satinizar_vistas(vistas)\n",
    "    vistas.idaviso = vistas.idaviso.astype('int64')\n",
    "    postulantes = agregar_cantidad_anuncios(postulantes, 'anuncios_vistos', vistas)\n",
    "    postulaciones = pd.read_csv(\n",
    "        'datos/datos_navent/fiuba_4_postulaciones.csv'\n",
    "    ).merge(pd.read_csv('datos/hasta_15_4/fiuba_4_postulaciones.csv'))\n",
    "    postulaciones = sanitize_postulaciones(postulaciones)\n",
    "    avisos_detalle = pd.concat([\n",
    "        pd.read_csv('datos/datos_navent/fiuba_6_avisos_detalle.csv'),\n",
    "        pd.read_csv('datos/hasta_15_4/fiuba_6_avisos_detalle.csv'),\n",
    "        pd.read_csv('datos/fiuba_6_avisos_detalle_missing_nivel_laboral.csv')\n",
    "    ])\n",
    "    #ESTE DF TIENE MUCHOS DATOS NULOS EN LAS COLUMNAS DE 'CIUDAD' y 'MAPACALLE'. \n",
    "    #Decidimos eliminarlas ya que no nos parecieron muy relevantes para el analisis\n",
    "    #idpais solo tiene valor 1, la descripcion nunca es nula\n",
    "    #avisos_detalle.drop('descripcion',1,inplace=True)\n",
    "    avisos_detalle.nombre_area.value_counts()# hay muchas areas, no van a tener su propia categoria\n",
    "    avisos_detalle = sanitize_aviso_detalle(avisos_detalle)\n",
    "    return postulantes, avisos_detalle, vistas, postulaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vasectomio/.virtualenv/datos/lib/python3.6/site-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/home/vasectomio/.virtualenv/datos/lib/python3.6/site-packages/ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  del sys.path[0]\n",
      "/home/vasectomio/.virtualenv/datos/lib/python3.6/site-packages/ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/home/vasectomio/.virtualenv/datos/lib/python3.6/site-packages/ipykernel_launcher.py:15: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "postulantes, avisos_detalle, vistas, postulaciones = leer_datos_entrenamiento()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CategoricalIndex(['RANDSTAD', 'Manpower', 'Grupo Gestión', 'Assistem',\n",
       "                  'Pullmen Servicios Empresarios S.A.', 'BAYTON',\n",
       "                  'Consultores de Empresas SRL', 'Suministra',\n",
       "                  'Adecco -Región Office', 'SOLUTIX S.A. ',\n",
       "                  ...\n",
       "                  'Rotativos Ares SA', 'LINIO ARGENTINA', 'Expassio',\n",
       "                  'IMPORTANTE EMPRESA ZONA SUR.', 'Gespo',\n",
       "                  'PROYECTO EDUCATIVO 2000 S A', 'CLADD I.T.A.S.A.',\n",
       "                  'estudio Santaromia', 'MJPS DISTRIBUIDORA',\n",
       "                  'iMaat, Agencia de Marketing Digital'],\n",
       "                 categories=['MJPS DISTRIBUIDORA', 'Domestico Lanus', 'MS CONTADORA', 'PAGLIALUNGA MARIELA MERCEDES', 'Colegio Generación', 'Próximo Contact Center', 'PLUS', 'AMOBA', ...], ordered=True, dtype='category', length=3517)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avisos_detalle.denominacion_empresa.value_counts().index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pruebo un random forest, con solamente las variables numericas/categoricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def armar_dataframe_forest(postulantes, avisos, vistas, postulaciones, proporcion_entrenamiento):\n",
    "    avisos_forest =  avisos.drop(['titulo','descripcion'],1)\n",
    "    joined = postulantes.merge(\n",
    "        vistas.loc[:,['idpostulante','idaviso']],on='idpostulante',how='left'\n",
    "    ).merge(\n",
    "        avisos_forest,on='idaviso',how='left'\n",
    "    )\n",
    "    if proporcion_entrenamiento != 0 and postulaciones is not None:\n",
    "        postulaciones_forest = postulaciones.loc[:,['idaviso','idpostulante']]\n",
    "        postulaciones_forest['sepostulo'] = 1\n",
    "        joined = joined.merge(\n",
    "            postulaciones_forest,on=['idaviso','idpostulante'],how='left'\n",
    "        )\n",
    "        joined.sepostulo = joined.sepostulo.fillna(0)\n",
    "        joined['es_entrenamiento'] = np.random.uniform(0, 1, joined.shape[0]) <= proporcion_entrenamiento\n",
    "    features = [it for it in joined.columns if it not in ['idaviso','idpostulante','es_entrenamiento','sepostulo']]\n",
    "    categorical_coulumns = joined.select_dtypes(['category']).columns\n",
    "    joined[categorical_coulumns] = joined[categorical_coulumns].apply(lambda it: it.cat.codes)\n",
    "    return joined, features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_forest, features = armar_dataframe_forest(postulantes, avisos_detalle, vistas, postulaciones, 0.75)\n",
    "classifier = RandomForestClassifier(n_jobs=5, random_state=0)\n",
    "#classifier.fit(df_entrenamiento[features], df_entrenamiento.sepostulo.astype('int64').values)\n",
    "train, test = df_forest[df_forest.es_entrenamiento],df_forest[~df_forest.es_entrenamiento]\n",
    "classifier.fit(train[features], train.sepostulo.astype('int64').values)\n",
    "\n",
    "results = classifier.predict(test[features])\n",
    "roc_auc_score(y_true=test.sepostulo.astype('int64').values,y_score=results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_forest.idaviso.isna().value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A partir de aqui, tengo armado el dataframe de entrenamiento\n",
    "por lo que no necesito ya los dataframes 'crudos'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "89"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#del avisos_detalle, postulaciones, postulantes, vistas, features\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vasectomio/.virtualenv/datos/lib/python3.6/site-packages/ipykernel_launcher.py:15: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "nuevos_postulantes = sanitize_postulante_genero_edad(pd.read_csv('datos/desde_15_4/fiuba_2_postulantes_genero_y_edad.csv'))\n",
    "nuevos_postulantes = generar_nivel_educativo(nuevos_postulantes, pd.read_csv('datos/desde_15_4/fiuba_1_postulantes_educacion.csv'))\n",
    "nuevas_vistas = satinizar_vistas(pd.read_csv('datos/desde_15_4/fiuba_3_vistas.csv'))\n",
    "nuevos_postulantes = agregar_cantidad_anuncios(nuevos_postulantes, 'anuncios_vistos', nuevas_vistas)\n",
    "nuevos_avisos = sanitize_aviso_detalle(pd.concat([\n",
    "    pd.read_csv('datos/desde_15_4/fiuba_6_avisos_detalle.csv'),\n",
    "    pd.read_csv('datos/fiuba_6_avisos_detalle_missing_nivel_laboral.csv')#\n",
    "]))\n",
    "template_submit = pd.read_csv('datos/template_resultado.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clasificar_random_forest(classifier, postulantes, avisos, template_submit):\n",
    "    df_predicciones, features = armar_dataframe_forest(postulantes, avisos, vistas, None, 0)\n",
    "    df_predicciones['sepostulo'] = classifier.predict(df_predicciones[features])\n",
    "    return df_predicciones.loc[:,['idaviso','idpostulante','sepostulo']]\n",
    "tentativo_submit = clasificar_random_forest(classifier, nuevos_postulantes, nuevos_avisos, nuevas_vistas)\n",
    "tentativo_submit = tentativo_submit.merge(template_submit, on=['idaviso','idpostulante'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4166187, 9)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#postulantes.drop(['fechanacimiento'],1).merge(\n",
    "    #vistas.loc[:,['idpostulante','idaviso']],on='idpostulante',how='left'\n",
    "#).merge(\n",
    "\n",
    "# No hay vistas que no tengan un \n",
    "nuevas_vistas.loc[:,['idpostulante','idaviso']].merge(nuevos_avisos, on='idaviso',how='inner').isna().shape#.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = RandomForestClassifier(n_jobs=5, random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = dict(max_features = [0.5,0.75],\n",
    "                    min_samples_leaf= [2,4,7,12,19],\n",
    "                    n_estimators = [5,10,30,50]\n",
    "                 )\n",
    "# caso entrenado con muchos datos\n",
    "df_forest, features = armar_dataframe_forest(postulantes, avisos_detalle, vistas, postulaciones, 0.75)\n",
    "train, test = df_forest[df_forest.es_entrenamiento],df_forest[~df_forest.es_entrenamiento]\n",
    "classifier = RandomForestClassifier(n_jobs=5, random_state=0)\n",
    "grid_bien_entrenada = GridSearchCV(estimator=classifier, n_jobs=2, param_grid=param_grid)\n",
    "grid_bien_entrenada.fit(train[features], train.sepostulo.astype('int64').values)\n",
    "print(\"La matriz bien entrenada logro un puntaje de \", grid_bien_entrenada.best_score_,\" con parametros \", grid_bien_entrenada.best_params_)\n",
    "#Caso entrenado con pocos datos\n",
    "df_forest, features = armar_dataframe_forest(postulantes, avisos_detalle, vistas, postulaciones, 0.25)\n",
    "train, test = df_forest[df_forest.es_entrenamiento],df_forest[~df_forest.es_entrenamiento]\n",
    "classifier = RandomForestClassifier(n_jobs=5, random_state=0)\n",
    "grid_poco_entrenada = GridSearchCV(estimator=classifier, n_jobs=2, param_grid=param_grid)\n",
    "grid_poco_entrenada.fit(train[features], train.sepostulo.astype('int64').values)\n",
    "print(\"La matriz poco entrenada logro un puntaje de \", grid_poco_entrenada.best_score_,\" con parametros \", grid_poco_entrenada.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generar un resultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tentativa = pd.read_csv('datos/template_resultado.csv')\n",
    "submit = pd.DataFrame()\n",
    "submit['id'] = tentativa['id']\n",
    "submit = submit.set_index('id')\n",
    "submit['sepostulo'] =0\n",
    "submit.to_csv(path_or_buf='submit.csv')\n",
    "submit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defino los shingles de cada anuncio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shingles(string, n = 3):\n",
    "    return [string[i:i + n] for i in range(len(string) - n + 1)]\n",
    "\n",
    "def jaccard_similarity(list1, list2):\n",
    "    intersection = len(list(set(list1).intersection(list2)))\n",
    "    print(set(list1).intersection(list2))\n",
    "    union = (len(list1) + len(list2)) - intersection\n",
    "    print(union)\n",
    "    return float(intersection / union)\n",
    "#avisos_detalle['shingles_descripcion'] = avisos_detalle.descripcion.apply(shingles)\n",
    "#avisos_detalle['shingles_titulo'] = avisos_detalle.titulo.apply(shingles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
