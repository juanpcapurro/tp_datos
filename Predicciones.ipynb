{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib_venn import venn2\n",
    "import numpy as np\n",
    "import seaborn as sbn\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import time\n",
    "import gc\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from pandas.api.types import CategoricalDtype\n",
    "\n",
    "%matplotlib inline\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "plt.style.use('default') \n",
    "sbn.set(style=\"whitegrid\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Satinización de archivos de edad y genero**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def postulantes_str2timestamp(s): # debo\n",
    "    if type(s) is datetime:\n",
    "        return s\n",
    "    try:\n",
    "        return datetime.strptime(s, '%Y-%m-%d')\n",
    "    except:\n",
    "        return None\n",
    "def sanitize_postulante_genero_edad(df):\n",
    "    df['sexo'] = df['sexo'].astype('category').fillna(\"NO_DECLARA\")\n",
    "    df = df.drop_duplicates(subset='idpostulante')\n",
    "    df['fechanacimiento']= df['fechanacimiento'].map(postulantes_str2timestamp)\n",
    "    mean_datetime = datetime.now()\n",
    "    df['fechanacimiento']= df['fechanacimiento'].map(lambda it: it if it else mean_datetime)\n",
    "    df['edad'] = df.fechanacimiento.apply(lambda it: 2018 - it.year)\n",
    "    #df = df[df.edad >17][df.edad<105]\n",
    "    return df.drop(['fechanacimiento'],1)\n",
    "def generar_nivel_educativo(postulantes, educacion):\n",
    "    #Considero como nivel educativo el maximo nivel que alcanzaron que fue completado.\n",
    "    #Descarto estudios en curso o abandonados, quizas deba volver aca en algun momento\n",
    "    tipo_estudio = CategoricalDtype(\n",
    "        categories=[\"Otro\",\"Secundario\",\"Terciario/Técnico\",\"Universitario\",\"Posgrado\",\"Master\",\"Doctorado\"],\n",
    "        ordered=True\n",
    "    )\n",
    "    educacion = educacion[educacion.estado=='Graduado'].drop(['estado'],1)\n",
    "    educacion.nombre= educacion.nombre.astype(tipo_estudio)\n",
    "    educacion = educacion.sort_values(by='nombre',ascending=True)\n",
    "    educacion = educacion.drop_duplicates(subset='idpostulante',keep='last')\n",
    "    postulantes = postulantes.merge(educacion, on='idpostulante',how='left')\n",
    "    postulantes = postulantes.rename(index=str,columns={'nombre':'nivel_educativo'})\n",
    "    print(\"postulantes sin nivel educativo: \",postulantes.nivel_educativo.isna().value_counts())\n",
    "    return postulantes\n",
    "def satinizar_vistas(vistas):\n",
    "    vistas = vistas.drop_duplicates().rename(columns={'idAviso': 'idaviso'})\n",
    "    #vistas.date = pd.to_datetime(vistas.timestamp).dt.date\n",
    "    vistas.idaviso = vistas.idaviso.astype('int64')\n",
    "    #return vistas.loc[:,['idaviso','date','idpostulante']]\n",
    "    return vistas.loc[:,['idaviso','timestamp','idpostulante']]\n",
    "\n",
    "def sanitize_aviso_detalle(df):\n",
    "    df = df.drop_duplicates(subset='idaviso')\n",
    "    tipo_trabajo = CategoricalDtype(\n",
    "        categories=[\"Full-time\",\"Part-time\",\"Teletrabajo\",\"Por Horas\",\"Pasantia\",\"Temporario\",\"Por Contrato\",\"Fines de Semana\",\"Primer empleo\"],\n",
    "        ordered=True #de 'mas fijo' a 'menos fijo'\n",
    "    )\n",
    "    df['tipo_de_trabajo'] = df['tipo_de_trabajo'].astype(tipo_trabajo)\n",
    "    # el numero quizas amerite tratarse como hiperparametro\n",
    "    #empresas_reconocidas = df.denominacion_empresa.value_counts().index[:100]\n",
    "    #df.loc[:,'denominacion_empresa'] = df.denominacion_empresa.apply(lambda it: it if it in empresas_reconocidas else 'Otro')\n",
    "    popularidad_empresa = CategoricalDtype(\n",
    "        categories=df.denominacion_empresa.value_counts(ascending=True).index,\n",
    "        ordered=True\n",
    "    )\n",
    "    df.loc[:,'denominacion_empresa'] = df.loc[:,'denominacion_empresa'].astype(popularidad_empresa)\n",
    "    for columna in ['nombre_zona','nombre_area','nivel_laboral']:\n",
    "        df.loc[:,columna] = df.loc[:,columna].astype('category')\n",
    "    #df.nivel_laboral = df.nivel_laboral.fillna('Otro')\n",
    "    #df.denominacion_empresa = df.denominacion_empresa.fillna('Otro')\n",
    "    return df.drop(['ciudad','idpais','mapacalle'],1)\n",
    "def sanitize_postulaciones(df):\n",
    "    df['date'] = pd.to_datetime(df['fechapostulacion']).dt.date\n",
    "    df['time'] = pd.to_datetime(df['fechapostulacion']).dt.time\n",
    "    df = df[pd.to_datetime(df.fechapostulacion) > datetime(2018,2,23,18,38)]\n",
    "    return df.drop_duplicates(subset=['idpostulante','idanuncio'],keep='last')\n",
    "def agregar_cantidad_anuncios(df, nombre_columna, anuncios):\n",
    "    values = pd.DataFrame()\n",
    "    value_counts = anuncios['idpostulante'].value_counts()\n",
    "    values['idpostulante'] = value_counts.index\n",
    "    values[nombre_columna] = value_counts.values\n",
    "    df = pd.merge(df,values, on='idpostulante',how='left')\n",
    "    df[nombre_columna] = df[nombre_columna].fillna(0)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Antes que nada, me intriga si los archivos de 'datos_navent' y los de 'hasta15/4' tienen overlap, son redundantes o consecutivos\n",
    "def leer_datos_entrenamiento():\n",
    "    genero_edad_postulantes = pd.concat([\n",
    "        pd.read_csv('datos/datos_navent/fiuba_2_postulantes_genero_y_edad.csv'),\n",
    "        pd.read_csv('datos/hasta_15_4/fiuba_2_postulantes_genero_y_edad.csv')\n",
    "    ])\n",
    "    #veo que hay repetidos por id\n",
    "    #veo que hay gente (4) con sexo '0'\n",
    "    # Genero una funcion para satinizar archivos de postulantes_genero_edad\n",
    "    genero_edad_postulantes = sanitize_postulante_genero_edad(genero_edad_postulantes)\n",
    "    educacion_postulantes = pd.concat([\n",
    "        pd.read_csv('datos/datos_navent/fiuba_1_postulantes_educacion.csv'),\n",
    "        pd.read_csv('datos/hasta_15_4/fiuba_1_postulantes_educacion.csv')\n",
    "    ])\n",
    "    postulantes = generar_nivel_educativo(genero_edad_postulantes, educacion_postulantes)\n",
    "    vistas = pd.concat([\n",
    "        pd.read_csv('datos/hasta_15_4/fiuba_3_vistas.csv'),\n",
    "        pd.read_csv('datos/datos_navent/fiuba_3_vistas.csv')\n",
    "    ])\n",
    "    vistas = satinizar_vistas(vistas)\n",
    "    vistas.idaviso = vistas.idaviso.astype('int64')\n",
    "    postulantes = agregar_cantidad_anuncios(postulantes, 'anuncios_vistos', vistas)\n",
    "    postulaciones = pd.concat([\n",
    "        pd.read_csv('datos/datos_navent/fiuba_4_postulaciones.csv'),\n",
    "        pd.read_csv('datos/hasta_15_4/fiuba_4_postulaciones.csv')\n",
    "    ])\n",
    "    postulaciones = sanitize_postulaciones(postulaciones)\n",
    "    avisos_detalle = pd.concat([\n",
    "        pd.read_csv('datos/datos_navent/fiuba_6_avisos_detalle.csv'),\n",
    "        pd.read_csv('datos/hasta_15_4/fiuba_6_avisos_detalle.csv'),\n",
    "        pd.read_csv('datos/fiuba_6_avisos_detalle_missing_nivel_laboral.csv')\n",
    "    ])\n",
    "    #ESTE DF TIENE MUCHOS DATOS NULOS EN LAS COLUMNAS DE 'CIUDAD' y 'MAPACALLE'. \n",
    "    #Decidimos eliminarlas ya que no nos parecieron muy relevantes para el analisis\n",
    "    #idpais solo tiene valor 1, la descripcion nunca es nula\n",
    "    #avisos_detalle.drop('descripcion',1,inplace=True)\n",
    "    tipo_trabajo = CategoricalDtype(\n",
    "        categories=[\"Full-time\",\"Part-time\",\"Teletrabajo\",\"Por Horas\",\"Pasantia\",\"Temporario\",\"Por Contrato\",\"Fines de Semana\",\"Primer empleo\"],\n",
    "        ordered=True #de 'mas fijo' a 'menos fijo'\n",
    "    )\n",
    "    avisos_detalle.nombre_area.value_counts()# hay muchas areas, no van a tener su propia categoria\n",
    "    avisos_detalle = sanitize_aviso_detalle(avisos_detalle)\n",
    "    return postulantes, avisos_detalle, vistas, postulaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def leer_datos_predicciones():\n",
    "    vistas = satinizar_vistas(pd.read_csv('datos/desde_15_4/fiuba_3_vistas.csv'))\n",
    "    avisos = sanitize_aviso_detalle(pd.concat([\n",
    "        pd.read_csv('datos/desde_15_4/fiuba_6_avisos_detalle.csv'),\n",
    "        pd.read_csv('datos/fiuba_6_avisos_detalle_missing_nivel_laboral.csv')#\n",
    "    ]))\n",
    "    genero_edad_postulantes = sanitize_postulante_genero_edad(\n",
    "        pd.concat([\n",
    "            pd.read_csv('datos/desde_15_4/fiuba_2_postulantes_genero_y_edad.csv'),\n",
    "            pd.read_csv('datos/hasta_15_4/fiuba_2_postulantes_genero_y_edad.csv')\n",
    "        ])\n",
    "    )\n",
    "    postulantes = generar_nivel_educativo(genero_edad_postulantes, pd.read_csv('datos/desde_15_4/fiuba_1_postulantes_educacion.csv'))\n",
    "    postulantes = agregar_cantidad_anuncios(postulantes, 'anuncios_vistos', vistas)\n",
    "    template_submit = pd.read_csv('datos/template_resultado.csv')\n",
    "    return postulantes, avisos, vistas, template_submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vasectomio/.virtualenvs/datos/lib/python3.6/site-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/home/vasectomio/.virtualenvs/datos/lib/python3.6/site-packages/ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  del sys.path[0]\n",
      "/home/vasectomio/.virtualenvs/datos/lib/python3.6/site-packages/ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "postulantes sin nivel educativo:  False    290986\n",
      "True     117160\n",
      "Name: nivel_educativo, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vasectomio/.virtualenvs/datos/lib/python3.6/site-packages/ipykernel_launcher.py:45: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/vasectomio/.virtualenvs/datos/lib/python3.6/site-packages/pandas/core/indexing.py:537: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "76"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "postulantes, avisos_detalle, vistas, postulaciones = leer_datos_entrenamiento()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pruebo un random forest, con solamente las variables numericas/categoricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def codificar_categoricas(df):\n",
    "    categorical_coulumns = df.select_dtypes(['category']).columns\n",
    "    df[categorical_coulumns] = df[categorical_coulumns].apply(lambda it: it.cat.codes)\n",
    "    return df\n",
    "def armar_dataframe_forest(postulantes, avisos, vistas, postulaciones, proporcion_entrenamiento):\n",
    "    avisos_forest =  avisos.drop(['titulo','descripcion'],1)\n",
    "    joined = postulantes.merge(\n",
    "        vistas.loc[:,['idpostulante','idaviso']],on='idpostulante',how='left'\n",
    "    ).merge(\n",
    "        avisos_forest,on='idaviso',how='left'\n",
    "    )\n",
    "    #joined['visto'] = 1\n",
    "    #random_relationships = pd.DataFrame()\n",
    "    #random_relationships = avisos.sample(random_state=0)\n",
    "    if proporcion_entrenamiento != 0 and postulaciones is not None:\n",
    "        postulaciones_forest = postulaciones.loc[:,['idaviso','idpostulante']]\n",
    "        postulaciones_forest['sepostulo'] = 1\n",
    "        joined = joined.merge(\n",
    "            postulaciones_forest,on=['idaviso','idpostulante'],how='left'\n",
    "        )\n",
    "        joined.sepostulo = joined.sepostulo.fillna(0)\n",
    "        joined['es_entrenamiento'] = np.random.uniform(0, 1, joined.shape[0]) <= proporcion_entrenamiento\n",
    "    features = [it for it in joined.columns if it not in ['id','idaviso','idpostulante','es_entrenamiento','sepostulo']]\n",
    "    joined = codificar_categoricas(joined)\n",
    "    return joined, features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_forest, features = armar_dataframe_forest(postulantes, avisos_detalle, vistas, postulaciones, 0.99)\n",
    "df_forest = df_forest.reset_index()\n",
    "classifier = RandomForestClassifier(n_jobs=5, random_state=0)\n",
    "#classifier.fit(df_entrenamiento[features], df_entrenamiento.sepostulo.astype('int64').values)\n",
    "train, test = df_forest[df_forest.es_entrenamiento],df_forest[~df_forest.es_entrenamiento]\n",
    "classifier.fit(train[features], train.sepostulo.astype('int64').values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8404823701073915"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = classifier.predict(test[features])\n",
    "roc_auc_score(y_true=test.sepostulo.astype('int64').values,y_score=results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A partir de aqui, tengo armado el dataframe de entrenamiento\n",
    "por lo que no necesito ya los dataframes 'crudos'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vasectomio/.virtualenvs/datos/lib/python3.6/site-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/home/vasectomio/.virtualenvs/datos/lib/python3.6/site-packages/ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  del sys.path[0]\n",
      "/home/vasectomio/.virtualenvs/datos/lib/python3.6/site-packages/ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "postulantes sin nivel educativo:  True     216660\n",
      "False    203830\n",
      "Name: nivel_educativo, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "181"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()\n",
    "#du.fu.du.du.du\n",
    "postulantes, avisos, vistas, submit = leer_datos_predicciones()\n",
    "del postulaciones\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sepostulo originalmente nulo:  False    99988\n",
      "True        12\n",
      "Name: sepostulo, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def clasificar_random_forest(classifier, postulantes, avisos, template_submit):\n",
    "    df_predicciones = template_submit.merge(\n",
    "        postulantes, on='idpostulante', how='inner'\n",
    "    ).merge(\n",
    "        avisos, on='idaviso',how='inner'\n",
    "    )\n",
    "    df_predicciones = codificar_categoricas(df_predicciones)\n",
    "    df_predicciones = df_predicciones.drop(['titulo','descripcion'],1)\n",
    "    features = [it for it in df_predicciones.columns if it not in ['id','idaviso','idpostulante','es_entrenamiento','sepostulo']]\n",
    "    df_predicciones['sepostulo'] = classifier.predict(df_predicciones[features])\n",
    "    df_predicciones = df_predicciones.merge(\n",
    "        submit, how='right',on=['idaviso','idpostulante','id']\n",
    "    ).loc[:,['id','sepostulo']].set_index('id')\n",
    "    print(\"sepostulo originalmente nulo: \",df_predicciones.sepostulo.isna().value_counts())\n",
    "    df_predicciones.sepostulo = df_predicciones.sepostulo.fillna(0).astype('int64')\n",
    "    return df_predicciones\n",
    "tentativo_submit = clasificar_random_forest(classifier, postulantes, avisos, submit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    95351\n",
       "1     4649\n",
       "Name: sepostulo, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tentativo_submit.to_csv(path_or_buf='submit.csv')\n",
    "tentativo_submit.sepostulo.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = RandomForestClassifier(n_jobs=5, random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = dict(max_features = [0.5,0.75],\n",
    "                    min_samples_leaf= [2,4,7,12,19],\n",
    "                    n_estimators = [5,10,30,50]\n",
    "                 )\n",
    "# caso entrenado con muchos datos\n",
    "df_forest, features = armar_dataframe_forest(postulantes, avisos_detalle, vistas, postulaciones, 0.75)\n",
    "train, test = df_forest[df_forest.es_entrenamiento],df_forest[~df_forest.es_entrenamiento]\n",
    "classifier = RandomForestClassifier(n_jobs=5, random_state=0)\n",
    "grid_bien_entrenada = GridSearchCV(estimator=classifier, n_jobs=2, param_grid=param_grid)\n",
    "grid_bien_entrenada.fit(train[features], train.sepostulo.astype('int64').values)\n",
    "print(\"La matriz bien entrenada logro un puntaje de \", grid_bien_entrenada.best_score_,\" con parametros \", grid_bien_entrenada.best_params_)\n",
    "#Caso entrenado con pocos datos\n",
    "df_forest, features = armar_dataframe_forest(postulantes, avisos_detalle, vistas, postulaciones, 0.25)\n",
    "train, test = df_forest[df_forest.es_entrenamiento],df_forest[~df_forest.es_entrenamiento]\n",
    "classifier = RandomForestClassifier(n_jobs=5, random_state=0)\n",
    "grid_poco_entrenada = GridSearchCV(estimator=classifier, n_jobs=2, param_grid=param_grid)\n",
    "grid_poco_entrenada.fit(train[features], train.sepostulo.astype('int64').values)\n",
    "print(\"La matriz poco entrenada logro un puntaje de \", grid_poco_entrenada.best_score_,\" con parametros \", grid_poco_entrenada.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generar un resultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defino los shingles de cada anuncio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shingles(string, n = 3):\n",
    "    return [string[i:i + n] for i in range(len(string) - n + 1)]\n",
    "\n",
    "def jaccard_similarity(list1, list2):\n",
    "    intersection = len(list(set(list1).intersection(list2)))\n",
    "    print(set(list1).intersection(list2))\n",
    "    union = (len(list1) + len(list2)) - intersection\n",
    "    print(union)\n",
    "    return float(intersection / union)\n",
    "#avisos_detalle['shingles_descripcion'] = avisos_detalle.descripcion.apply(shingles)\n",
    "#avisos_detalle['shingles_titulo'] = avisos_detalle.titulo.apply(shingles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
